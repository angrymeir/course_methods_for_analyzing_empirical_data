{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Strength of relationships in an empirical context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Analysis\n",
    "The assignment asks to employ linear regression for predictive modelling, to find the best models using different combinations of predictors and the statistical significance of the relationship between the predictors and the model outcome.  \n",
    "For that purpose, we employ:\n",
    "- Linear Regression\n",
    "- Mean Squared Error\n",
    "- P-Values\n",
    "- Confidence Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the methods' use case?\n",
    "\n",
    "##### Linear Regression\n",
    "- Models the linear relationship between two variables\n",
    "\n",
    "##### Mean Squared Error\n",
    "- Metric to calculate the error between an estimation and the true value\n",
    "- In our case evaluates how well the model estimates the truth\n",
    "\n",
    "##### P-Values\n",
    "- Probability to measure data that is in tune with the null hypothesis\n",
    "- In our case whether the relationship observed between a variable and the prediction result is statistically significant\n",
    "\n",
    "##### Confidence Intervals\n",
    "- Offer an interval within which the true value of a variable is likely to fall with a certain level of confidence\n",
    "- In our case we use it instead of p-values to make a statement about the statistical significance of the variables relationship\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Methods\n",
    "##### Linear Regression\n",
    "Linear regression is a statistical technique to model the linear relationship between a dependent variable, and one or more independent variables. If used as a prediction, the dependent variable is the outcome of the prediction, and the independent variables (also called predictors) are the input.\n",
    "Since it is a linear relation in a potentially high-dimensional space (input is a n-dimensional vector), we aim at fitting a hyperplane through the data points. A hyperplane for a 1-dimensional input is a straight line, for a 2-dimensional input a plane etc.\n",
    "\n",
    "As such, the linear regression is described by n+2 coefficients (with n being the input dimension):\n",
    "$$ y = \\beta_0 + \\hat{\\beta_1} \\cdot \\hat{X} + \\hat{\\epsilon} $$\n",
    "\n",
    "Those coefficients are:\n",
    "- $y$ is the dependent one-dimensional variable\n",
    "- $\\hat{\\beta_1}$ is a n-dimensional vector, that determines how much impact changes to the predictors have on the dependent variable\n",
    "- $\\beta_0$ called the intercept, or the basis, is a one-dimensional variable. It holds the expected value of the dependent variable all predictors are 0.\n",
    "- $\\hat{\\epsilon}$ describes the error, it is n-dimensional vector. Since the model will not be able to perfectly describe all datapoints, the error aims to account for that shortcoming. Each entry of $\\hat{epsilon}$ has a mean of zero, and a variance of the sum of the squares of the errors of the predictions divided by the number of datapoints - 2\n",
    "\n",
    "**Example**  \n",
    "| dep. var. | ind. var.1 | ind. var.2 |\n",
    "|:---------:|:----------:|:----------:|\n",
    "| 262 | 22 | 1 |\n",
    "| 568 | 50 | 2 |\n",
    "| 319 | 25 | 2 |\n",
    "| 359 | 31 | 1 |\n",
    "| 276 | 23 | 1 |\n",
    "| 541 | 47 | 2 |\n",
    "\n",
    "From this data, the linear regression would be:\n",
    "$$ \\hat{y} = 20 + \\begin{bmatrix} 10 \\\\ 24 \\end{bmatrix} \\cdot \\hat{X} + 8 $$\n",
    "\n",
    "**Assumptions**  \n",
    "- Relationship between dependent and independent variables is linear\n",
    "- The independent variables are independent from each other\n",
    "- The training data is uncorrelated, as otherwise the errors would not be normal distributed and hence $\\hat{\\epsilon}$ impacted\n",
    "- The errors are normally distributed (as otherwise $\\hat{\\epsilon}$)\n",
    "\n",
    "##### Mean Squared Error\n",
    "The mean squared error estimates how well our model performs by comparing the predicted dependent variable with the actual dependent variable. It is calculated as follows:\n",
    "\n",
    "$$ MSE = \\frac{1}{n} \\sum_{i=1}^n(Y_i - Y^{'}_i)^2$$ \n",
    "with\n",
    "- $Y_i$ actual dependent variable\n",
    "- $Y^{'}_i$ predicted dependent variable\n",
    "- $n$ is the number of datapoints\n",
    "\n",
    "**Example**  \n",
    "| $Y$ | $Y^{'} |\n",
    "|:---------:|:----------:|\n",
    "| 265 | 262 |\n",
    "| 570 | 568 |\n",
    "| 320 | 319 |\n",
    "| 355 | 359 |\n",
    "| 275 | 276 |\n",
    "| 540 | 541 |\n",
    "\n",
    "Given this data, the $MSE = 5.3$\n",
    "\n",
    "\n",
    "##### P-Values\n",
    "The p-value is used in hypothesis testing to determine the probability of obtaining the results we got under the assumption, that the null hypothesis is correct. The null hypothesis states that the hypothesis (e.g. predictor A is relevant for the prediction) we are making does not hold. As such the p-value is used to estimated the statistical significance of the results for our hypothesis. A low p-value (commonly 5%) shows, that it is unlikely that we obtained the results (e.g. good performance of linear regression) while our hypothesis is wrong (predictor is irrelevant). A high p-value indicates, that the null hypothesis might be correct (and hence the predictor irrelevant for prediction).\n",
    "\n",
    "**Assumptions**  \n",
    "- Normal distribution or a large sample size as the p-value might be inaccurate otherwise\n",
    "\n",
    "##### Confidence Intervals\n",
    "While p-values give information on whether to reject the null hypothesis and assume that the hypothesis we made holds, the have limited information content e.g.\n",
    "- should we reject a hypothesis if the p-value is 0.06?\n",
    "- what is the size of the effect/how much uncertainty is involved?\n",
    "- what is the effect?\n",
    "\n",
    "Confidence intervals address those questions by providing an interval within which the true value of the variable in question (e.g. coefficient of linear regression) lies with a high confidence (e.g. 95%). By providing a range, we don't have to make a decision based on a single value (0.05 break off point), but based on a range (e.g. between 0.3 and 0.7).\n",
    "\n",
    "The effect size can also be better estimated, as the size of the interval tells us how well we understand the variable in question's effect size. Small intervals imply, that we have a good understanding and can be more confident in the statistical significance/non-significance, while wide intervals imply higher uncertainty, even if there is a statistical significance.\n",
    "\n",
    "The effect can be easily seen by the intervals. If the intervals are purely positive (e.g. [0.3 - 0.7]), the effect will also likely be positive. If the intervals are purely negative (e.g. [-0.7 - -0.3]), the effect will also likely be negative. If the intervals cover 0, it will probably be statistically insignificant, as the variable in question could also be 0, hence have no influence on the effect.\n",
    "\n",
    "To calculate the confidence intervals for the regression coefficients, we follow the following formula:\n",
    "\n",
    "$$ [\\text{CI}_1, \\text{CI}_2] = \\hat{X} \\pm t_{\\alpha/2} \\times \\hat{\\epsilon} $$\n",
    "\n",
    "with:\n",
    "- $[\\text{CI}_1, \\text{CI}_2]$ being the lower and the upper bound of the interval\n",
    "- $\\hat{X}$ being the statistical mean of the regression coefficient we want to get the confidence intervals for\n",
    "- $t_{\\alpha/2}$ being the critical value, so the point separating where we accept or reject the null hypothesis. More explanation about critical values below. Alpha denotes the expected confidence level (typically 5% as with p-values).\n",
    "- $\\hat{\\epsilon}$ being the error of the logistic regression for that coefficient\n",
    "\n",
    "**Assumptions**  \n",
    "- Data should be sampled at random and the datapoints should be independent of each other since the calculated standard error will be inacurrately reflect the true value of the data\n",
    "- The critical value has to be specified correctly based on the samples. E.g. either the data set is big enough, or a t-distribution should be used\n",
    "- Outliers will affect the error and in turn impact the confidence intervals\n",
    "\n",
    "##### Critical Value\n",
    "The critical value is determine by the conditions under which it is applied. For example, the sample size has an impact on the whether which value to use. If the sample size is large and from a normal distribution we would use the z-value, if the sample size is low (as it is in our case), we'd follow the t-value. Also, whether we simply look at one side of the distribution or on both sides has an effect on the critical value as we can see in the differences of the t-value tables [here](https://www.scribbr.com/statistics/students-t-table/). Also the degree of freedom is impacts the critical value, without going into detail, for our case this is the sample size - 2 degrees of freedom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the methods' assumptions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Failure</th>\n",
       "      <th>SDL pages</th>\n",
       "      <th>Tasks</th>\n",
       "      <th>Outputs</th>\n",
       "      <th>Inputs</th>\n",
       "      <th>If</th>\n",
       "      <th>States</th>\n",
       "      <th>McCabe (design)</th>\n",
       "      <th>Ext. input</th>\n",
       "      <th>Ext. Output</th>\n",
       "      <th>Internal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>68</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>76</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>131</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>85</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>39</td>\n",
       "      <td>11</td>\n",
       "      <td>80</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>68</td>\n",
       "      <td>24</td>\n",
       "      <td>19</td>\n",
       "      <td>59</td>\n",
       "      <td>13</td>\n",
       "      <td>99</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>42</td>\n",
       "      <td>33</td>\n",
       "      <td>36</td>\n",
       "      <td>27</td>\n",
       "      <td>39</td>\n",
       "      <td>105</td>\n",
       "      <td>39</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Failure  SDL pages  Tasks  Outputs  Inputs  If  States  McCabe (design)  \\\n",
       "0        0          9     68       16      14  21       1               83   \n",
       "1        0         14     76       33      34  30       2              131   \n",
       "2        0         15     85       18      19  39      11               80   \n",
       "3        0         18     68       24      19  59      13               99   \n",
       "4        1         18     42       33      36  27      39              105   \n",
       "\n",
       "   Ext. input  Ext. Output  Internal  \n",
       "0          10           11         0  \n",
       "1          21           21         0  \n",
       "2          17           16         1  \n",
       "3          18           18         2  \n",
       "4          39           36         3  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import r_regression, SelectKBest\n",
    "from scipy import stats\n",
    "\n",
    "df = pd.read_csv('data/table_1.csv', delimiter=\";\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first split the data into train and test, so that we have a common benchmark across all approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train at test data\n",
    "X = df.drop('Failure', axis=1)\n",
    "y = df['Failure']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define the function to calculate the confidence intervals. \n",
    "Here we follow exactly the approach described above.\n",
    "\n",
    "We take the trained linear regression model and calculate the errors for each coefficient. Afterward we calculate the critical value under the assumption of a confidence of 95%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute confidence intervals for coefficients\n",
    "def compute_confidence_intervals(model, X_train, features=None, alpha=0.05):\n",
    "    if features is None:\n",
    "        features = X_train.columns\n",
    "        \n",
    "    # Number of observations and number of features\n",
    "    n = len(X_train)\n",
    "    p = len(features)\n",
    "    \n",
    "    # Predict the values\n",
    "    predictions = model.predict(X_train[features])\n",
    "    \n",
    "    # Compute the residuals\n",
    "    residuals = predictions - y_train\n",
    "    \n",
    "    # Estimate the variance of the residuals\n",
    "    s_squared = np.sum(residuals**2) / (n - p - 1)\n",
    "    \n",
    "    # Get the covariance matrix of the coefficients\n",
    "    X_design = np.column_stack((np.ones(n), X_train[features]))\n",
    "    covariance_matrix = s_squared * np.linalg.inv(np.dot(X_design.T, X_design))\n",
    "    \n",
    "    # Compute standard errors for the coefficients\n",
    "    standard_errors = np.sqrt(np.diag(covariance_matrix))\n",
    "    \n",
    "    # Get coefficients\n",
    "    coefficients = np.insert(model.coef_, 0, model.intercept_)\n",
    "    \n",
    "    # Compute the t-statistic for the confidence interval\n",
    "    t_value = stats.t.ppf(1 - alpha / 2, df=n - p - 1)\n",
    "    \n",
    "    # Compute confidence intervals\n",
    "    ci_lower = coefficients - t_value * standard_errors\n",
    "    ci_upper = coefficients + t_value * standard_errors\n",
    "    \n",
    "    # Return a DataFrame with results\n",
    "    ci_df = pd.DataFrame({\n",
    "        'Feature': ['Intercept'] + list(features),\n",
    "        'Coefficient': coefficients,\n",
    "        'CI Lower': ci_lower,\n",
    "        'CI Upper': ci_upper\n",
    "    })\n",
    "    return ci_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Relation between one other variable and failures\n",
    "We perform this with two different variables. One that has a strong correlation and one without a strong correlation (as we know from assignment 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_strong_corr_train, no_strong_corr_test = X_train[['Inputs']], X_test[['Inputs']]\n",
    "strong_corr_train, strong_corr_test = X_train[['Ext. Output']], X_test[['Ext. Output']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for model trained on no correlation data:  9.065658138242265\n",
      "MSE for model trained on strongly correlating data:  6.813614130922394\n",
      "\n",
      "\n",
      "Confidence intervals for no correlation model: \n",
      "      Feature  Coefficient  CI Lower  CI Upper\n",
      "0  Intercept     2.053288 -1.434419  5.540995\n",
      "1     Inputs     0.023155 -0.012146  0.058456\n",
      "\n",
      "\n",
      "Confidence intervals for strong correlation model: \n",
      "        Feature  Coefficient  CI Lower  CI Upper\n",
      "0    Intercept    -0.938776 -4.385015  2.507464\n",
      "1  Ext. Output     0.104956  0.039687  0.170226\n"
     ]
    }
   ],
   "source": [
    "no_corr_model = LinearRegression()\n",
    "no_corr_model.fit(no_strong_corr_train, y_train)\n",
    "no_corr_y_pred = no_corr_model.predict(no_strong_corr_test)\n",
    "\n",
    "strong_corr_model = LinearRegression()\n",
    "strong_corr_model.fit(strong_corr_train, y_train)\n",
    "strong_corr_y_pred = strong_corr_model.predict(strong_corr_test)\n",
    "\n",
    "print(\"MSE for model trained on no correlation data: \", mean_squared_error(y_test, no_corr_y_pred))\n",
    "print(\"MSE for model trained on strongly correlating data: \", mean_squared_error(y_test, strong_corr_y_pred))\n",
    "\n",
    "no_corr_ci_info = compute_confidence_intervals(no_corr_model, no_strong_corr_train)\n",
    "strong_corr_ci_info = compute_confidence_intervals(strong_corr_model, strong_corr_train)\n",
    "\n",
    "print(\"\\n\\nConfidence intervals for no correlation model: \\n\", no_corr_ci_info)\n",
    "print(\"\\n\\nConfidence intervals for strong correlation model: \\n\", strong_corr_ci_info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary \n",
    "- The model trained with the strongly correlated feature works better than the one trained on a less well correlated feature as its MSE is lower.\n",
    "- Since the confidence interval for *Inputs* and *Intercept* entails 0, there is no statistical significance to the relationship we found\n",
    "- Since the confidence interval for *Intercept* entails 0, it is not relevant to the dependent variable (the outcome), however, the variable *Ext. Output* does not entail 0 and is entirely positive. Hence, *Ext. Output* is a strong indicator for the prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Relation between all other variables and failures\n",
    "We take all variables and directly fit the model with them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for model trained on all variables:  50.28866355248625\n",
      "\n",
      "\n",
      "Confidence intervals for all variables model: \n",
      "             Feature  Coefficient  CI Lower  CI Upper\n",
      "0         Intercept    -2.424003 -5.703283  0.855278\n",
      "1         SDL pages    -0.104220 -0.317585  0.109145\n",
      "2             Tasks     0.021164 -0.002560  0.044887\n",
      "3           Outputs     0.034339 -0.118030  0.186708\n",
      "4            Inputs    -0.138221 -0.335758  0.059315\n",
      "5                If    -0.007306 -0.085013  0.070401\n",
      "6            States     0.018851 -0.036690  0.074391\n",
      "7   McCabe (design)     0.014516 -0.031965  0.060996\n",
      "8        Ext. input     0.045089 -0.468234  0.558412\n",
      "9       Ext. Output     0.135704 -0.391612  0.663021\n",
      "10         Internal     0.270688 -0.307389  0.848765\n"
     ]
    }
   ],
   "source": [
    "all_variables_model = LinearRegression()\n",
    "all_variables_model.fit(X_train, y_train)\n",
    "all_variables_y_pred = all_variables_model.predict(X_test)\n",
    "print(\"MSE for model trained on all variables: \", mean_squared_error(y_test, all_variables_y_pred))\n",
    "\n",
    "all_ci_info = compute_confidence_intervals(all_variables_model, X_train)\n",
    "\n",
    "print(\"\\n\\nConfidence intervals for all variables model: \\n\", all_ci_info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this trained model...\n",
    "- the MSE is high, hence taking all variables as predictors results in bad performance\n",
    "- the relations of all variables with the predictive outcome are statistically insignificant since all their confidence intervals entail 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Relation between a subset of the variables and failures\n",
    "We stepwise increase the number of variables as predictors for the logistic regression.  \n",
    "For that purpose we always select the k best variables according to each predictors f-statistic and p-values.  \n",
    "Afterward we train each model with the select variables and analyze its performance via the mean squared error.\n",
    "The best performing model is returned in combination with its mean squared error and the used features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for 1 features: ['Ext. Output'] is 6.813614130922394\n",
      "MSE for 2 features: ['Ext. input' 'Ext. Output'] is 6.720501004557096\n",
      "MSE for 3 features: ['Tasks' 'Ext. input' 'Ext. Output'] is 9.286361248707918\n",
      "MSE for 4 features: ['Tasks' 'If' 'Ext. input' 'Ext. Output'] is 12.77032717403539\n",
      "MSE for 5 features: ['SDL pages' 'Tasks' 'If' 'Ext. input' 'Ext. Output'] is 8.788209930238608\n",
      "MSE for 6 features: ['SDL pages' 'Tasks' 'If' 'McCabe (design)' 'Ext. input' 'Ext. Output'] is 25.97848822968942\n",
      "MSE for 7 features: ['SDL pages' 'Tasks' 'Outputs' 'If' 'McCabe (design)' 'Ext. input'\n",
      " 'Ext. Output'] is 26.35131480694719\n",
      "MSE for 8 features: ['SDL pages' 'Tasks' 'Outputs' 'Inputs' 'If' 'McCabe (design)'\n",
      " 'Ext. input' 'Ext. Output'] is 61.411666022642244\n",
      "MSE for 9 features: ['SDL pages' 'Tasks' 'Outputs' 'Inputs' 'If' 'States' 'McCabe (design)'\n",
      " 'Ext. input' 'Ext. Output'] is 61.0343643314943\n",
      "\n",
      "\n",
      "Best MSE: 6.720501004557096 with features: ['Ext. input' 'Ext. Output']\n",
      "\n",
      "Confidence Intervals for the best model:\n",
      "       Feature  Coefficient  CI Lower  CI Upper\n",
      "0    Intercept    -0.964238 -4.547738  2.619262\n",
      "1   Ext. input    -0.023084 -0.338197  0.292029\n",
      "2  Ext. Output     0.128567 -0.200736  0.457869\n"
     ]
    }
   ],
   "source": [
    "def select_features(k, X_train, y_train):\n",
    "    selector = SelectKBest(r_regression, k=k)\n",
    "    selector.fit(X_train, y_train)\n",
    "    return selector.get_feature_names_out()\n",
    "\n",
    "def evaluate_features(features, X_train, X_test, y_train, y_test):\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train[features], y_train)\n",
    "    y_pred = model.predict(X_test[features])\n",
    "    return mean_squared_error(y_test, y_pred), model\n",
    "\n",
    "best_mse = float('inf')\n",
    "best_features = []\n",
    "best_model = None\n",
    "for k in range(1, X_train.shape[1]):\n",
    "    features = select_features(k, X_train, y_train)\n",
    "    mse, model = evaluate_features(features, X_train, X_test, y_train, y_test)\n",
    "    if mse < best_mse:\n",
    "        best_mse = mse\n",
    "        best_features = features\n",
    "        best_model = model\n",
    "    print(f\"MSE for {k} features: {features} is {mse}\")\n",
    "\n",
    "print(f\"\\n\\nBest MSE: {best_mse} with features: {best_features}\")\n",
    "\n",
    "if best_model:\n",
    "    ci_df = compute_confidence_intervals(best_model, X_train, best_features)\n",
    "    print(\"\\nConfidence Intervals for the best model:\")\n",
    "    print(ci_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "- The best predictive results are achieve when using the variable *Ext. input* and *Ext. Output*\n",
    "- While promising, neither of the variables' relations to the predictive results are statistically significant"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
